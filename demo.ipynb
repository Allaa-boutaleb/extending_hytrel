{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import search.unionable_table_search as uts\n",
    "import search.joinable_table_search as jts\n",
    "import post_processing.filtering_reranking as fr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](pipeline_illustration.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unionable Table Search \n",
    "Once the data lake embeddings have been computed following the instructions described in [here](embedding_computation/README.md), we can execute unionable table search. <br>\n",
    "In this demo, we have already computed embeddings for SANTOS data lake provided with SANTOS benchmark with the following configurations [#0](embedding_computation/experiments.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalake_embeddings = './output/hytrel_embedding/santos/hytrel_datalake_columns_0.pkl'\n",
    "query_embeddings = './output/hytrel_embedding/santos/hytrel_query_columns_0.pkl'\n",
    "k = 10\n",
    "## select a query dataset\n",
    "with open(query_embeddings, 'rb') as f:\n",
    "    query_columns_hytrel = pickle.load(f)\n",
    "with open(datalake_embeddings, 'rb') as f:\n",
    "    datalake_columns_hytrel = pickle.load(f)\n",
    "query_table = query_columns_hytrel[0] ## corresponding to 'cihr_co-applicant_b.csv'\n",
    "candidates, build_duration, query_duration = uts.approximate_unionable_dataset_search([query_columns_hytrel[0]], datalake_columns_hytrel,k,compress_method='max')\n",
    "candidates = candidates['cihr_co-applicant_b.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: cihr_co-applicant_b.csv\n",
      "candidate in 2 place: cihr_co-applicant_9.csv\n",
      "candidate in 3 place: cihr_co-applicant_7.csv\n",
      "candidate in 4 place: cihr_co-applicant_6.csv\n",
      "candidate in 5 place: cihr_co-applicant_8.csv\n",
      "candidate in 6 place: cihr_co-applicant_3.csv\n",
      "candidate in 7 place: cihr_co-applicant_5.csv\n",
      "candidate in 8 place: cihr_co-applicant_1.csv\n",
      "candidate in 9 place: cihr_co-applicant_0.csv\n",
      "candidate in 10 place: cihr_co-applicant_2.csv\n",
      "Index build duration: 0.0042572021484375\n",
      "Query duration: 0.0001938343048095703\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')\n",
    "\n",
    "print(f'Index build duration: {build_duration}')\n",
    "print(f'Query duration: {query_duration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering-based search \n",
    "Once the embeddings have been computed. We can preform hierarchal clustering on the computed data lake embeddings. Instructions to compute heirarchal clustering can be found [here](clustering/) <br>\n",
    "In this demo, we have ran clustering on column embeddings with configuration [0](/embedding_computation/experiments.md) and cluster count of [811](clustering/experiments.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m clustering \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/clustering/santos/clustering_811_santos_run_id_0.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(clustering, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     clustering_result \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m datalake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(clustering_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()))\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcihr_co-applicant_b.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/hytrel/lib/python3.11/site-packages/pandas/core/internals/blocks.py:2728\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, refs)\u001b[0m\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_block\u001b[39m(\n\u001b[1;32m   2717\u001b[0m     values,\n\u001b[1;32m   2718\u001b[0m     placement: BlockPlacement,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2725\u001b[0m     \u001b[38;5;66;03m# - check_ndim/ensure_block_shape already checked\u001b[39;00m\n\u001b[1;32m   2726\u001b[0m     \u001b[38;5;66;03m# - maybe_coerce_values already called/unnecessary\u001b[39;00m\n\u001b[1;32m   2727\u001b[0m     klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2728\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m klass(values, ndim\u001b[38;5;241m=\u001b[39mndim, placement\u001b[38;5;241m=\u001b[39mplacement, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)"
     ]
    }
   ],
   "source": [
    "clustering = './output/clustering/santos/clustering_811_santos_run_id_0.pkl'\n",
    "with open(clustering, 'rb') as f:\n",
    "    clustering_result = pickle.load(f)\n",
    "datalake = list(set(clustering_result['dataset'].unique()))\n",
    "query = 'cihr_co-applicant_b.csv'\n",
    "k = 10\n",
    "res = uts.unionable_table_search_using_clustering([query], datalake, clustering_result,k)\n",
    "candidates = res[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: cihr_co-applicant_b.csv\n",
      "candidate in 2 place: cihr_co-applicant_6.csv\n",
      "candidate in 3 place: cihr_co-applicant_0.csv\n",
      "candidate in 4 place: cihr_co-applicant_1.csv\n",
      "candidate in 5 place: cihr_co-applicant_3.csv\n",
      "candidate in 6 place: cihr_co-applicant_4.csv\n",
      "candidate in 7 place: cihr_co-applicant_9.csv\n",
      "candidate in 8 place: cihr_co-applicant_5.csv\n",
      "candidate in 9 place: cihr_co-applicant_7.csv\n",
      "candidate in 10 place: cihr_co-applicant_2.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joinable Table Search\n",
    "Once the data lake embeddings have been computed following the instructions described in [here](embedding_computation/README.md), we can execute unionable table search. <br>\n",
    "In this demo, we have already computed embeddings for NextiaJD testbedS data lake provided with NextiaJD benchmark with the following configurations [#4](embedding_computation/experiments.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_datalake_columns:  2553\n",
      "build regular index using faiss\n",
      "number of queries: 1\n"
     ]
    }
   ],
   "source": [
    "datalake_embeddings = './output/hytrel_embedding/nextiajd/testbedS/hytrel_datalake_columns_4.pkl'\n",
    "query_embeddings = './output/hytrel_embedding/nextiajd/testbedS/hytrel_query_columns_4.pkl'\n",
    "with open(query_embeddings, 'rb') as f:\n",
    "    query_columns_hytrel = pickle.load(f)\n",
    "with open(datalake_embeddings, 'rb') as f:\n",
    "    datalake_columns_hytrel = pickle.load(f)\n",
    "\n",
    "res, build_duration, query_duration = jts.joinable_dataset_search([query_columns_hytrel[61]], datalake_columns_hytrel,1000,'testbedS')\n",
    "candidates = res[('agri-environmental-indicators-emissions-by-sector.csv',\n",
    "  'Area')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country')\n",
      "candidate in 2 place: ('global-greenhouse-gas-emissions0.csv', 'Country')\n",
      "candidate in 3 place: ('global-innovation-index-2015.csv', 'COUNTRY_NAME')\n",
      "candidate in 4 place: ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY')\n",
      "candidate in 5 place: ('global-greenhouse-gas-emissions.csv', 'Country')\n",
      "candidate in 6 place: ('listings_summary.csv', 'host_name')\n",
      "candidate in 7 place: ('makemytrip_com-travel_sample.csv', 'city')\n",
      "candidate in 8 place: ('listings_detailed.csv', 'host_name')\n",
      "candidate in 9 place: ('listings_summary.csv', 'host_neighbourhood')\n",
      "candidate in 10 place: ('listings_summary.csv', 'neighbourhood')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing: Filtering, and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LSH ensemble for query ('agri-environmental-indicators-emissions-by-sector.csv', 'Area')\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/agri-environmental-indicators-emissions-by-sector.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/emissions_agriculture_energy_e_all_data_norm.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-greenhouse-gas-emissions0.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-innovation-index-2015.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/population-estimates-and-projections-1960-2050.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-greenhouse-gas-emissions.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/makemytrip_com-travel_sample.csv\n",
      "delimiter: ,\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_detailed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/post_processing/filtering_reranking.py:26: DtypeWarning: Columns (43,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n"
     ]
    }
   ],
   "source": [
    "datalake_source = '/Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets'\n",
    "filtered,overlap_est = fr.run_lsh_ensemble(datalake_source, res, num_perm=256, threshold=0.5, num_part=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('agri-environmental-indicators-emissions-by-sector.csv',\n",
       "  'Area'): [('emissions_agriculture_energy_e_all_data_norm.csv',\n",
       "   'Country'), ('global-greenhouse-gas-emissions0.csv', 'Country'), ('global-greenhouse-gas-emissions.csv',\n",
       "   'Country'), ('global-innovation-index-2015.csv', 'COUNTRY_NAME')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country') in the original list ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country')\n",
      "candidate in 2 place: ('global-greenhouse-gas-emissions0.csv', 'Country') in the original list ('global-greenhouse-gas-emissions0.csv', 'Country')\n",
      "candidate in 3 place: ('global-greenhouse-gas-emissions.csv', 'Country') in the original list ('global-innovation-index-2015.csv', 'COUNTRY_NAME')\n",
      "candidate in 4 place: ('global-innovation-index-2015.csv', 'COUNTRY_NAME') in the original list ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY')\n",
      "candidate in 5 place: ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY') in the original list ('global-greenhouse-gas-emissions.csv', 'Country')\n",
      "candidate in 6 place: ('listings_summary.csv', 'host_name') in the original list ('listings_summary.csv', 'host_name')\n",
      "candidate in 7 place: ('makemytrip_com-travel_sample.csv', 'city') in the original list ('makemytrip_com-travel_sample.csv', 'city')\n",
      "candidate in 8 place: ('listings_detailed.csv', 'host_name') in the original list ('listings_detailed.csv', 'host_name')\n",
      "candidate in 9 place: ('listings_summary.csv', 'host_neighbourhood') in the original list ('listings_summary.csv', 'host_neighbourhood')\n",
      "candidate in 10 place: ('listings_summary.csv', 'neighbourhood') in the original list ('listings_summary.csv', 'neighbourhood')\n"
     ]
    }
   ],
   "source": [
    "reranked = fr.rank_table(overlap_est)\n",
    "candidates_reranked = reranked[('agri-environmental-indicators-emissions-by-sector.csv',\n",
    "  'Area')]\n",
    "for i in range(len(candidates_reranked)):\n",
    "    print(f'candidate in {i+1} place: {candidates_reranked[i]} in the original list {candidates[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
